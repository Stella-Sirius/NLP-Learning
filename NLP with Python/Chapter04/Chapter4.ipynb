{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Structured Programs #\n",
    "\n",
    "https://www.nltk.org/book/ch04.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested = [[]] * 3\n",
    "nested[1].append('Python')\n",
    "nested[1] = ['Monty']\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "size = 5\n",
    "python = ['Python']\n",
    "snake_nest = [python] * size\n",
    "position = random.choice(range(size))\n",
    "snake_nest[position] = ['Python']\n",
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4383536072, 4383536072, 4383536072, 4383537352, 4383536072]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionals ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "mixed = ['cat', '', ['dog'], []]\n",
    "for element in mixed:\n",
    "    if element:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "animals = ['cat', 'dog']\n",
    "if 'cat' in animals:\n",
    "    print(1)\n",
    "elif 'dog' in animals:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    "all(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequences ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'fem', 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'walk', 'fem', 3 \n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fem', 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I turned off the spectroroute'\n",
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "pair = (6, 'turned')\n",
    "raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[-3:], text[-3:], pair[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Python Expression|Comment|\n",
    "|----|----|\n",
    "|for item in s|iterate over the items of s|\n",
    "|for item in sorted(s)|iterate over the items of s in order|\n",
    "|for item in set(s)|iterate over unique elements of s|\n",
    "|for item in reversed(s)|iterate over elements of s in reverse|\n",
    "|for item in set(s).difference(t)|iterate over elements of s not in t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1; lorry: 4; ,: 3; yellow: 2; red: 1; .: 1; "
     ]
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(key + ':', fdist[key], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1a15bd2848>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some NLP tasks it is necessary to cut up a sequence into two or more parts. For instance, we might want to \"train\" a system on 90% of the data and test it on the remaining 10%. To do this we decide the location where we want to cut the data , then cut the sequence at that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.nps_chat.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(0.9 * len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Different Sequence Types ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " words = 'I turned off the spectroroute'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'I'), (6, 'turned'), (3, 'off'), (3, 'the'), (12, 'spectroroute')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlens = [(len(word), word) for word in words]\n",
    "wordlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlens.sort()\n",
    "' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = [('the', 'det', ['Di:', 'D@']),('off', 'prep', ['Qf', 'O:f'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Expressions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " '...',\n",
       " '``',\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\n",
    "... \"it means just what I choose it to mean - neither more nor less.\"'''\n",
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(w.lower() for w in nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions of Style ###\n",
    "**Procedural vs Declarative Style**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.401545438271973"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.corpus.brown.words(categories='news')\n",
    "count = 0\n",
    "total = 0\n",
    "for token in tokens:\n",
    "    count += 1\n",
    "    total += len(token)\n",
    "total / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "total = sum(len(t) for t in tokens)\n",
    "print(total / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())\n",
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()]\n",
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"%3d %6.2f%% %s\" % (rank + 1, cumulative * 100, word))\n",
    "    if cumulative > 0.25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unextinguishable'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')\n",
    "longest = ''\n",
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "        longest = word\n",
    "\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(len(word) for word in text)\n",
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Legitimate Uses for Counters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object bigrams at 0x1a1ca701b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.bigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object trigrams at 0x1a1ca70228>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.trigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngrams at 0x1a1ca702a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.ngrams(text, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions: The Foundation of Structured Programming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_text(file):\n",
    "    \"\"\"Read text from a file, normalizing whitespace and stripping HTML markup.\"\"\"\n",
    "    text = open(file).read()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_text in module __main__:\n",
      "\n",
      "get_text(file)\n",
      "    Read text from a file, normalizing whitespace and stripping HTML markup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking Parameter Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    assert isinstance(word, list), \"argument to tag() must be a string\"\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functional Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, freqdist, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "    for word in nltk.word_tokenize(raw):\n",
    "        freqdist[word.lower()] += 1\n",
    "    result = []\n",
    "    for word, count in freqdist.most_common(n):\n",
    "        result = result + [word]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"''\", ',', ':', ':1', 'the', ';', '(', ')', '``', '{', '}', 'of', '?', 'url', 'https', '@', 'import', 'q8ad82', \"'\", 'archives', '#', 'and', '.', '[', ']', 'national', 'a', 'documents', 'founding', 'to']\n"
     ]
    }
   ],
   "source": [
    "constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\"\n",
    "fd = nltk.FreqDist()\n",
    "freq_words(constitution, fd, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Documenting Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing More with Functions ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions as Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the', 'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_property(prop):\n",
    "    return [prop(word) for word in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_letter(word):\n",
    "    return word[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(last_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'Take',\n",
       " 'and',\n",
       " 'care',\n",
       " 'care',\n",
       " 'of',\n",
       " 'of',\n",
       " 'sense',\n",
       " 'sounds',\n",
       " 'take',\n",
       " 'the',\n",
       " 'the',\n",
       " 'themselves',\n",
       " 'will']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accumulative Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search1('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "for item in search2('zz', nltk.corpus.brown.words()):\n",
    "    print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "    else:\n",
    "        for perm in permutations(seq[1:]):\n",
    "            for i in range(len(perm)+1):\n",
    "                yield perm[:i] + seq[0:1] + perm[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(permutations(['police', 'fish', 'buffalo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Higher-Order Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_word(word):\n",
    "    return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the','sounds', 'will', 'take', 'care', 'of', 'themselves', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = list(map(len, nltk.corpus.brown.sents(categories='news')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in nltk.corpus.brown.sents(categories='news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Named Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(msg='<empty>', num=1):\n",
    "    return msg * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<empty><empty><empty>'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AliceAliceAliceAliceAlice'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(num=5, msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "generic(1, \"African swallow\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = [['four', 'calling', 'birds'],['three', 'French', 'hens'],['two', 'turtle', 'doves']]\n",
    "list(zip(song[0], song[1], song[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'French', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10):\n",
    "    text = open(file).read()\n",
    "    tokens = word_tokenize(text)\n",
    "    freqdist = nltk.FreqDist(t for t in tokens if len(t) >= min)\n",
    "    return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(file, min=1, num=10, verbose=False):\n",
    "    freqdist = FreqDist()\n",
    "    if verbose: print(\"Opening\", file)\n",
    "    text = open(file).read()\n",
    "    if verbose: print(\"Read in %d characters\" % len(file))\n",
    "    for word in word_tokenize(text):\n",
    "        if len(word) >= min:\n",
    "            freqdist[word] += 1\n",
    "            if verbose and freqdist.N() % 100 == 0: print(\".\", sep=\"\")\n",
    "    if verbose: print\n",
    "    return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omg', 'teh', 'teh', 'mat']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_words(text, wordlength, result=[]):\n",
    "    for word in text:\n",
    "        if len(word) == wordlength:\n",
    "            result.append(word)\n",
    "    return result\n",
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ur', 'on']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 2, ['ur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omg', 'teh', 'teh', 'mat', 'omg', 'teh', 'teh', 'mat']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_words(['omg', 'teh', 'lolcat', 'sitted', 'on', 'teh', 'mat'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Techniques ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omg', 'teh', 'teh', 'mat', 'omg', 'teh', 'teh', 'mat', 'cat']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdb\n",
    "find_words(['cat'], 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <string>(1)<module>()\n",
      "(Pdb) step\n",
      "--Call--\n",
      "> <ipython-input-93-78b138c17277>(1)find_words()\n",
      "-> def find_words(text, wordlength, result=[]):\n",
      "(Pdb) args\n",
      "text = ['dog']\n",
      "wordlength = 3\n",
      "result = ['omg', 'teh', 'teh', 'mat', 'omg', 'teh', 'teh', 'mat', 'cat']\n",
      "(Pdb) exit\n"
     ]
    }
   ],
   "source": [
    "pdb.run(\"find_words(['dog'], 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial1(n):\n",
    "    result = 1\n",
    "    for i in range(n):\n",
    "        result *= (i+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial2(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial2(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size1(s):\n",
    "    return 1 + sum(size1(child) for child in s.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    " def size2(s):\n",
    "    layer = [s] \n",
    "    total = 0\n",
    "    while layer:\n",
    "        total += len(layer) \n",
    "        layer = [h for c in layer for h in c.hyponyms()]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "dog = wn.synset('dog.n.01')\n",
    "size1(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size2(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "trie = dict(trie)               # for nicer printing\n",
    "trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Space-Time Tradeoffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Index...\n",
      "query> quit\n",
      "s funded by her mother . lucy quit working professionally 10\n",
      "erick . i disliked that movie quite a bit , but since \" prac\n",
      "t disaster . babe ruth didn't quit baseball after one season\n",
      "o-be fiance . i think she can quit that job and get a more r\n",
      " and rose mcgowan should just quit acting . she has no chari\n",
      "and get a day job . and don't quit it .                     \n",
      " kubrick , alas , should have quit while he was ahead . this\n",
      "everyone involved should have quit while they were still ahe\n",
      "l die . so what does joe do ? quit his job , of course ! ! w\n",
      "red \" implant . he's ready to quit the biz and get a portion\n",
      "hat he always recorded , they quit and become disillusioned \n",
      " admit that i ? ? ? ve become quite the \" scream \" fan . no \n",
      " again , the fact that he has quit his job to feel what it's\n",
      "school reunion . he has since quit his job as a travel journ\n",
      "ells one of his friends , \" i quit school because i didn't l\n",
      "ms , cursing off the boss and quitting his job ( \" today i q\n",
      "e , the arrival of the now ubiquitous videocassette . burt r\n",
      "in capitol city , that he has quit his job and hopes to open\n",
      "before his death at age 67 to quit filmmaking once a homosex\n",
      " - joss's explanation that he quit the priesthood because of\n",
      " is a former prosecutor , and quit because of tensions betwe\n"
     ]
    }
   ],
   "source": [
    "def raw(file):\n",
    "    contents = open(file).read()\n",
    "    contents = re.sub(r'<.*?>', ' ', contents)\n",
    "    contents = re.sub('\\s+', ' ', contents)\n",
    "    return contents\n",
    "\n",
    "def snippet(doc, term):\n",
    "    text = ' '*30 + raw(doc) + ' '*30\n",
    "    pos = text.index(term)\n",
    "    return text[pos-30:pos+30]\n",
    "\n",
    "print(\"Building Index...\")\n",
    "files = nltk.corpus.movie_reviews.abspaths()\n",
    "idx = nltk.Index((w, f) for f in files for w in raw(f).split())\n",
    "\n",
    "query = ''\n",
    "while query != \"quit\":\n",
    "    query = input(\"query> \")     # use raw_input() in Python 2\n",
    "    if query in idx:\n",
    "        for doc in idx[query]:\n",
    "            print(snippet(doc, query))\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tagged_corpus):\n",
    "    words = set()\n",
    "    tags = set()\n",
    "    for sent in tagged_corpus:\n",
    "        for word, tag in sent:\n",
    "            words.add(word)\n",
    "            tags.add(tag)\n",
    "    wm = dict((w, i) for (i, w) in enumerate(words))\n",
    "    tm = dict((t, i) for (i, t) in enumerate(tags))\n",
    "    return [[(wm[w], tm[t]) for (w, t) in sent] for sent in tagged_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029593479994218796\n"
     ]
    }
   ],
   "source": [
    "from timeit import Timer\n",
    "vocab_size = 100000\n",
    "setup_list = \"import random; vocab = range(%d)\" % vocab_size \n",
    "setup_set = \"import random; vocab = set(range(%d))\" % vocab_size \n",
    "statement = \"random.randint(0, %d) in vocab\" % (vocab_size * 2)\n",
    "print(Timer(statement, setup_list).timeit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001562788002047455\n"
     ]
    }
   ],
   "source": [
    "print(Timer(statement, setup_set).timeit(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dynamic Programming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virahanka1(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka1(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka1(n-2)]\n",
    "        return s + l\n",
    "\n",
    "def virahanka2(n):\n",
    "    lookup = [[\"\"], [\"S\"]]\n",
    "    for i in range(n-1):\n",
    "        s = [\"S\" + prosody for prosody in lookup[i+1]]\n",
    "        l = [\"L\" + prosody for prosody in lookup[i]]\n",
    "        lookup.append(s + l)\n",
    "    return lookup[n]\n",
    "\n",
    "def virahanka3(n, lookup={0:[\"\"], 1:[\"S\"]}):\n",
    "    if n not in lookup:\n",
    "        s = [\"S\" + prosody for prosody in virahanka3(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka3(n-2)]\n",
    "        lookup[n] = s + l\n",
    "    return lookup[n]\n",
    "\n",
    "from nltk import memoize\n",
    "@memoize\n",
    "def virahanka4(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka4(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka4(n-2)]\n",
    "        return s + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virahanka1(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virahanka2(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virahanka3(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virahanka4(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Sample of Python Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "\n",
    "colors = 'rgbcmyk' # red, green, blue, cyan, magenta, yellow, black\n",
    "\n",
    "def bar_chart(categories, words, counts):\n",
    "    \"Plot a bar chart showing counts for each word by category\"\n",
    "    ind = arange(len(words))\n",
    "    width = 1 / (len(categories) + 1)\n",
    "    bar_groups = []\n",
    "    for c in range(len(categories)):\n",
    "        bars = pyplot.bar(ind+c*width, counts[categories[c]], width,\n",
    "                         color=colors[c % len(colors)])\n",
    "        bar_groups.append(bars)\n",
    "    pyplot.xticks(ind+width, words)\n",
    "    pyplot.legend([b[0] for b in bar_groups], categories, loc='upper left')\n",
    "    pyplot.ylabel('Frequency')\n",
    "    pyplot.title('Frequency of Six Modal Verbs by Genre')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['news', 'religion', 'hobbies', 'government', 'adventure']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "cfdist = nltk.ConditionalFreqDist(\n",
    "              (genre, word)\n",
    "              for genre in genres\n",
    "              for word in nltk.corpus.brown.words(categories=genre)\n",
    "              if word in modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = {}\n",
    "for genre in genres:\n",
    "    counts[genre] = [cfdist[genre][word] for word in modals]\n",
    "\n",
    "bar_chart(genres, modals, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type: text/html\n",
      "\n",
      "<html><body>\n",
      "<img src=\"modals.png\"/>\n",
      "</body></html>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import use, pyplot\n",
    "use('Agg')\n",
    "pyplot.savefig('modals.png') \n",
    "print('Content-Type: text/html')\n",
    "print()\n",
    "print('<html><body>')\n",
    "print('<img src=\"modals.png\"/>')\n",
    "print('</body></html>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetworkX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def traverse(graph, start, node):\n",
    "    graph.depth[node.name] = node.shortest_path_distance(start)\n",
    "    for child in node.hyponyms():\n",
    "        graph.add_edge(node.name, child.name)\n",
    "        traverse(graph, start, child)\n",
    "\n",
    "def hyponym_graph(start):\n",
    "    G = nx.Graph() \n",
    "    G.depth = {}\n",
    "    traverse(G, start, start)\n",
    "    return G\n",
    "\n",
    "def graph_draw(graph):\n",
    "    nx.draw_graphviz(graph,\n",
    "         node_size = [16 * graph.degree(n) for n in graph],\n",
    "         node_color = [graph.depth[n] for n in graph],\n",
    "         with_labels = False)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.02')\n",
    "graph = hyponym_graph(dog)\n",
    "draw(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "input_file = open(\"lexicon.csv\", \"rb\")\n",
    "for row in csv.reader(input_file):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "cube = array([ [[0,0,0], [1,1,1], [2,2,2]],\n",
    "                   [[3,3,3], [4,4,4], [5,5,5]],\n",
    "                  [[6,6,6], [7,7,7], [8,8,8]] ])\n",
    "cube[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [6, 7, 8],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube[2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7],\n",
       "       [8, 8, 8]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube[2,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4472136 , -0.89442719],\n",
       "       [-0.89442719,  0.4472136 ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "a=array([[4,0], [3,-5]])\n",
    "u,s,vt = linalg.svd(a)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.32455532, 3.16227766])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678],\n",
       "       [-0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
