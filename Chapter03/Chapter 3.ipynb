{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Raw Text #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Text from the Web and from Disk##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text number 2554 is an English translation of Crime and Punishment, and we can access it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division  # Python 2 users only\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  tokenization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: ﻿The Project Gutenberg EBook of Crime and Punishment...>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'exceptionally',\n",
       " 'hot',\n",
       " 'evening',\n",
       " 'early',\n",
       " 'in',\n",
       " 'July',\n",
       " 'a',\n",
       " 'young',\n",
       " 'man',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'garret',\n",
       " 'in',\n",
       " 'which',\n",
       " 'he',\n",
       " 'lodged',\n",
       " 'in',\n",
       " 'S.',\n",
       " 'Place',\n",
       " 'and',\n",
       " 'walked',\n",
       " 'slowly',\n",
       " ',',\n",
       " 'as',\n",
       " 'though',\n",
       " 'in',\n",
       " 'hesitation',\n",
       " ',',\n",
       " 'towards',\n",
       " 'K.',\n",
       " 'bridge',\n",
       " '.',\n",
       " 'He',\n",
       " 'had',\n",
       " 'successfully']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1024:1062]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to discover unique strings that mark the beginning and the end, before trimming raw to be just the content and nothing else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"end of Project Gutenberg's Crime\")\n",
    "#when it finds the right value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw[5338:1157743]\n",
    "#choose the index between part 1 and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195769"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")\n",
    "#part I should be found in the beginning as 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with HTML ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BBC News story called Blondes to die out in 200 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get text out of HTML we will use a Python library called BeautifulSoup#\n",
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing RSS Feeds ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']\n",
    "#'Language Log'\n",
    "len(llog.entries)\n",
    "#15\n",
    "post = llog.entries[2]\n",
    "post.title\n",
    "#\"He's My BF\"\n",
    "content = post.content[0].value\n",
    "content[:70]\n",
    "#'<p>Today I was chatting with three of our visiting graduate students f'\n",
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "word_tokenize(raw)\n",
    "#['Today', 'I', 'was', 'chatting', 'with', 'three', 'of', 'our', 'visiting',\n",
    "#'graduate', 'students', 'from', 'the', 'PRC', '.', 'Thinking', 'that', 'I',\n",
    "#'was', 'being', 'au', 'courant', ',', 'I', 'mentioned', 'the', 'expression',\n",
    "#'DUI4XIANG4', '\\u5c0d\\u8c61', '(\"', 'boy', '/', 'girl', 'friend', '\"', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Local Files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('.')\n",
    "f = open('document.txt')\n",
    "raw = f.read()\n",
    "for line in f:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK's corpus files can also be accessed using these methods. We simply have to use nltk.data.find() to get the filename for any corpus item. Then we can open and read it in the way we just demonstrated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting encoded text from files##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line.encode('unicode_escape'))\n",
    "#b'Pruska Biblioteka Pa\\\\u0144stwowa. Jej dawne zbiory znane pod nazw\\\\u0105'\n",
    "#b'\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez'\n",
    "#b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y'\n",
    "#b'odnalezione po 1945 r. na terytorium Polski. Trafi\\\\u0142y do Biblioteki'\n",
    "#b'Jagiello\\\\u0144skiej w Krakowie, obejmuj\\\\u0105 ponad 500 tys. zabytkowych'\n",
    "#b'archiwali\\\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ń'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacute = '\\u0144'\n",
    "nacute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xc5\\x84'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacute.encode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions for Detecting Word Patterns ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Basic Meta-Characters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w in wordlist if re.search('ed$', w)]\n",
    "#['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The . wildcard symbol matches any single character. Suppose we have room in a crossword puzzle for an 8-letter word with j as its third letter and t as its sixth letter. In place of each blank cell we use a period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w for w in wordlist if re.search('^..j..t..$', w)]\n",
    "#['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
